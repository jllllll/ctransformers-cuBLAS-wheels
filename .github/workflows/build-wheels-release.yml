name: Build Wheels & Release

on:
  workflow_dispatch:
    inputs:
      version:
        description: 'Version tag of ctransformers to build'
        required: true
        type: string
  workflow_call:
    inputs:
      version:
        description: 'Version tag of ctransformers to build'
        required: true
        type: string

permissions:
  contents: write

jobs:
  build_binaries:
    name: ${{ matrix.os }} ${{ matrix.cuda }} ${{ matrix.releasetag }}
    runs-on: ${{ matrix.os }}
    strategy:
      matrix:
        os: [ubuntu-20.04, windows-latest]
        cuda: ["11.7.1", "11.8.0", "12.0.1", "12.1.0", "12.2.0"]
        releasetag: ["AVX","AVX2"]
    defaults:
      run:
        shell: pwsh
    env:
      CUDAVER: ${{ matrix.cuda }}
      AVXVER: ${{ matrix.releasetag }}
      CTRANSVER: ${{ inputs.version }}

    steps:
      - uses: actions/checkout@v4
        with:
          repository: 'marella/ctransformers'
          ref: ${{ inputs.version }}
          submodules: 'recursive'
          
      - name: Free Disk Space
        uses: jlumbroso/free-disk-space@v1.2.0
        if: runner.os == 'Linux'
        with:
          tool-cache: false
          android: true
          dotnet: true
          haskell: true
          large-packages: false
          swap-storage: false
          
      - name: Get Visual Studio Integration
        if: matrix.cuda != '12.2.0' && runner.os == 'Windows'
        uses: Jimver/cuda-toolkit@v0.2.10
        with:
          cuda: ${{ matrix.cuda }}
          method: 'network'
          sub-packages: '["visual_studio_integration"]'
          
      - name: Get Visual Studio Integration 12.2
        if: matrix.cuda == '12.2.0' && runner.os == 'Windows'
        run: |
          Invoke-RestMethod 'https://developer.download.nvidia.com/compute/cuda/12.2.0/network_installers/cuda_12.2.0_windows_network.exe' -OutFile "$env:RUNNER_TEMP\cudainstaller.exe"
          Start-Process "$env:RUNNER_TEMP\cudainstaller.exe" -wait -ArgumentList '-s visual_studio_integration_12.2'
          echo 'CUDA_PATH=C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v12.2' >> $env:GITHUB_ENV
          
      - name: Install Visual Studio Integration
        if: runner.os == 'Windows'
        run: |
          $x = (dir $env:CUDA_PATH -dir -recurse -depth 2).where({$_.name -eq 'visual_studio_integration'}).fullname
          $y = (dir $x -dir -recurse).where({$_.name -eq 'MSBuildExtensions'}).fullname + '\*'
          (gi 'C:\Program Files\Microsoft Visual Studio\2022\Enterprise\MSBuild\Microsoft\VC\*\BuildCustomizations').fullname.foreach({cp $y $_})
          
      - uses: actions/setup-python@v3
        with:
          python-version: "3.10"
        
      - name: Setup Mamba
        uses: conda-incubator/setup-miniconda@v2.2.0
        with:
          activate-environment: "build"
          python-version: "3.10"
          miniforge-variant: Mambaforge
          miniforge-version: latest
          use-mamba: true
          add-pip-as-python-dependency: true
          auto-activate-base: false
          
      - name: Install Dependencies
        run: |
          $cudaVersion = $env:CUDAVER
          $cudaChannels = ''
          $cudaNum = [int]$cudaVersion.substring($cudaVersion.LastIndexOf('.')+1)
          while ($cudaNum -ge 0) { $cudaChannels += '-c nvidia/label/cuda-' + $cudaVersion.Remove($cudaVersion.LastIndexOf('.')+1) + $cudaNum + ' '; $cudaNum-- }
          mamba install -y 'cuda' $cudaChannels.TrimEnd().Split()
          python -m pip install cmake
          
      - name: Build Binaries
        run: |
          $env:CUDA_PATH = $env:CONDA_PREFIX
          $env:CUDA_HOME = $env:CONDA_PREFIX
          $env:CUDATOOLKITDIR = $env:CONDA_PREFIX
          if ($IsLinux) {$env:LD_LIBRARY_PATH = $env:CONDA_PREFIX + '/lib:' + $env:LD_LIBRARY_PATH}
          $env:VERBOSE = 1
          if ([version]$env:CTRANSVER.TrimStart('v') -lt [version]'0.2.15') {$env:CUDAFLAGS = '-arch=all'}
          cmake -B build "-DCT_INSTRUCTIONS=$($env:AVXVER.ToLower())" -DCT_CUBLAS=ON -DCMAKE_CUDA_ARCHITECTURES=all
          cmake --build build --config Release
        
      - uses: actions/upload-artifact@v3
        with:
          name: ${{ matrix.releasetag }}-${{ matrix.cuda }}
          path: ./build/lib/*
          
  build_wheels:
    name: Build CUDA ${{ matrix.cuda }} ${{ matrix.releasetag }} Wheel
    runs-on: ubuntu-20.04
    needs: build_binaries
    strategy:
      matrix:
        cuda: ["11.7.1", "11.8.0", "12.0.1", "12.1.0", "12.2.0"]
        releasetag: ["AVX","AVX2"]
    defaults:
      run:
        shell: pwsh
    env:
      CUDAVER: ${{ matrix.cuda }}

    steps:
      - uses: actions/checkout@v4
        with:
          repository: 'marella/ctransformers'
          ref: ${{ inputs.version }}
          
      - uses: actions/setup-python@v3
        with:
          python-version: "3.10"
        
      - name: Remove Existing Binaries
        run: |
          Remove-Item $(Join-Path (Join-Path '.' 'ctransformers' 'lib','cuda' -resolve) '*')
          
      - uses: actions/download-artifact@v3
        with:
          name: ${{ matrix.releasetag }}-${{ matrix.cuda }}
          path: ./ctransformers/lib/cuda
        
      - name: Build Wheel
        run: |
          python -m pip install build wheel
          $env:CT_WHEEL = '1'
          $cudaVersion = $env:CUDAVER.Remove($env:CUDAVER.LastIndexOf('.')).Replace('.','')
          python -m build --wheel -C--build-option=egg_info "-C--build-option=--tag-build=+cu$cudaVersion"
          
      - name: Upload files to a GitHub release
        id: upload-release
        uses: svenstaro/upload-release-action@2.6.1
        continue-on-error: true
        with:
          file: ./dist/*.whl
          tag: ${{ matrix.releasetag }}
          file_glob: true
          make_latest: false
          overwrite: true
        
      - uses: actions/upload-artifact@v3
        if: steps.upload-release.outcome == 'failure'
        with:
          name: ${{ matrix.releasetag }}-wheel
          path: ./dist/*.whl